{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e31865c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from typing import Literal\n",
    "from pydantic import BaseModel\n",
    "from pydantic import Field\n",
    "import json\n",
    "\n",
    "load_dotenv()\n",
    "open_api_key=os.getenv(\"OPEN_API_KEY\")\n",
    "\n",
    "#Choosing model save tokens cost as expecting just generating text\n",
    "openai_model_id = \"gpt-4o-mini\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4facfc56",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "OpenAI.__init__() got an unexpected keyword argument 'model'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m## OpenAI is a wrapper in langchain used to access openai API internally\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;66;03m#openai_client = OpenAI()\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m llm = \u001b[43mOpenAI\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mopenai_model_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m         \u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;66;43;03m# make sure the same reply and standard responses especially in foundation\u001b[39;49;00m\n\u001b[32m      6\u001b[39m \u001b[43m    \u001b[49m\u001b[43mapi_key\u001b[49m\u001b[43m=\u001b[49m\u001b[43mopen_api_key\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtiktoken\u001b[39;00m\n\u001b[32m     11\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcount_input_tokens\u001b[39m(messages, model=openai_model_id):\n",
      "\u001b[31mTypeError\u001b[39m: OpenAI.__init__() got an unexpected keyword argument 'model'"
     ]
    }
   ],
   "source": [
    "\n",
    "## OpenAI is a wrapper in langchain used to access openai API internally\n",
    "#openai_client = OpenAI()\n",
    "llm = OpenAI(\n",
    "    model=openai_model_id,         \n",
    "    temperature=0,# make sure the same reply and standard responses especially in foundation\n",
    "    api_key=open_api_key\n",
    ")\n",
    "\n",
    "import tiktoken\n",
    "\n",
    "def count_input_tokens(messages, model=openai_model_id):\n",
    "    encoding = tiktoken.encoding_for_model(model)\n",
    "\n",
    "    # Rough estimate; OpenAI uses specific rules depending on the model\n",
    "    num_tokens = 0\n",
    "    for message in messages:\n",
    "        # Each message has {role, content}, sometimes name\n",
    "        num_tokens += 4  # every message has a role and tokens overhead\n",
    "        for key, value in message.items():\n",
    "            num_tokens += len(encoding.encode(value))\n",
    "    num_tokens += 2  # every reply is primed with <|start|>assistant\n",
    "    return num_tokens\n",
    "# Compute cost\n",
    "def compute_cost(input_tokens, output_tokens, model=\"gpt-4o-mini\"):\n",
    "    if model == \"gpt-3.5-turbo\":\n",
    "        input_cost = (input_tokens / 1000) * 0.0015\n",
    "        output_cost = (output_tokens / 1000) * 0.002\n",
    "    elif model == \"gpt-4\":\n",
    "        input_cost = (input_tokens / 1000) * 0.03\n",
    "        output_cost = (output_tokens / 1000) * 0.06\n",
    "    elif model == \"gpt-4-turbo\":\n",
    "        input_cost = (input_tokens / 1000) * 0.01\n",
    "        output_cost = (output_tokens / 1000) * 0.03\n",
    "    elif model == \"gpt-4o-mini\":\n",
    "        input_cost = (input_tokens / 1_000_000) * 0.15\n",
    "        output_cost = (output_tokens / 1_000_000) * 0.60\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown model: {model}\")\n",
    "\n",
    "    return input_cost + output_cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1af26db0",
   "metadata": {},
   "outputs": [],
   "source": [
    "story = \"\"\" USA the leader of the world\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ba9d98e",
   "metadata": {},
   "outputs": [],
   "source": [
    "##just like defining allowed choices in a listbox (dropdown) \n",
    "StoryCategory = Literal[\n",
    "    \"politics\", \"sports\", \"art\", \"technology\", \"economy\",\n",
    "    \"health\", \"entertainment\", \"science\",\n",
    "    \"not_specified\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3eee30b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we Define the object class that will map the outout to this class\n",
    "# this is not a simple class , but class with validation as ORM \n",
    "class NewsDetails(BaseModel):\n",
    "    \n",
    " #... means mandatory\n",
    " # description help the model to more concentrate on the task\n",
    "    story_category: StoryCategory = Field(..., description=\"Category of the news story.\")\n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa8181f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'properties': {'story_category': {'description': 'Category of the news story.',\n",
       "   'enum': ['politics',\n",
       "    'sports',\n",
       "    'art',\n",
       "    'technology',\n",
       "    'economy',\n",
       "    'health',\n",
       "    'entertainment',\n",
       "    'science',\n",
       "    'not_specified'],\n",
       "   'title': 'Story Category',\n",
       "   'type': 'string'}},\n",
       " 'required': ['story_category'],\n",
       " 'title': 'NewsDetails',\n",
       " 'type': 'object'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NewsDetails.model_json_schema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e8cf4df4",
   "metadata": {},
   "outputs": [],
   "source": [
    "details_extraction_messages = [\n",
    "    {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": \"\\n\".join([\n",
    "            \"You are an NLP data paraser.\",\n",
    "            \"Extract the category as mentioned in text.\",\n",
    "            \"Do not generate any introduction or conclusion, be straight to the point\"\n",
    "        ])\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"\\n\".join([\n",
    "            \"## Story:\",\n",
    "            story.strip(),\n",
    "            \"\",\n",
    "\n",
    "            \"## Pydantic Details:\",\n",
    "            json.dumps(\n",
    "                NewsDetails.model_json_schema(), ensure_ascii=False\n",
    "            ),\n",
    "            \"\",\n",
    "\n",
    "            \"## Story Details:\",\n",
    "            \"```json\"\n",
    "        ])\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ed35409c",
   "metadata": {},
   "outputs": [],
   "source": [
    "details_extraction_messages_evaluate = [\n",
    "    {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": \"\\n\".join([\n",
    "            \"provide the type of this news\"\n",
    "        ])\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"\\n\".join([\n",
    "            \"## Story:\",\n",
    "            story.strip(),\n",
    "            \"\",\n",
    "\n",
    "\n",
    "            \"## Story Details:\",\n",
    "            \"```json\"\n",
    "        ])\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b06fd8de",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9a746d30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The type of this news is likely a political or international relations commentary or analysis. It appears to focus on the role of the United States in global leadership.\n"
     ]
    }
   ],
   "source": [
    "## evaluate the output without fine-yuning\n",
    "chat_completion = openai_client.chat.completions.create(\n",
    "    messages=details_extraction_messages_evaluate,\n",
    "    model=openai_model_id,\n",
    "    temperature=0.2,\n",
    ")\n",
    "print(chat_completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "93537f0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "politics\n",
      "Input Tokens: 150\n",
      "Output Tokens: 8\n",
      "Total Tokens: 157\n",
      "Estimated Cost: $0.000027\n"
     ]
    }
   ],
   "source": [
    "## evaluate the output without fine-yuning\n",
    "chat_completion = openai_client.chat.completions.create(\n",
    "    messages=details_extraction_messages,\n",
    "    model=openai_model_id,\n",
    "    temperature=0.2,\n",
    ")\n",
    "#print(chat_completion.choices[0].message.content)\n",
    "print(json.loads(chat_completion.choices[0].message.content)[\"story_category\"])\n",
    "\n",
    "input_tokens = count_input_tokens(details_extraction_messages, model=openai_model_id)\n",
    "output_tokens = chat_completion.usage.completion_tokens\n",
    "total_tokens = chat_completion.usage.total_tokens\n",
    "\n",
    "print(\"Input Tokens:\", input_tokens)\n",
    "print(\"Output Tokens:\", output_tokens)\n",
    "print(\"Total Tokens:\", total_tokens)\n",
    "\n",
    "# Display cost\n",
    "cost = compute_cost(input_tokens, output_tokens, model=openai_model_id)\n",
    "print(f\"Estimated Cost: ${cost:.6f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "testenv1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
