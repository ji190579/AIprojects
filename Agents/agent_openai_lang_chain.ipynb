{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b89f4142",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain.agents import initialize_agent, Tool\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain_google_genai  import ChatGoogleGenerativeAI\n",
    "from langchain.agents.agent_types import AgentType\n",
    "from langchain_core.tools import tool\n",
    "from langchain.agents import create_tool_calling_agent, AgentExecutor\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "import gradio as gr\n",
    "#search for available flsht to roma on 20/06/2025\n",
    "load_dotenv()\n",
    "\n",
    "langchain_api_key = os.getenv(\"LANGCHAIN_API_KEY\")\n",
    "open_api_key=os.getenv(\"OPEN_API_KEY\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e0176c1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# search_flights\n",
    "@tool\n",
    "def search_flights(location: str, date: str) -> str:\n",
    "    \"\"\"Search for flights based on location and date.\"\"\"\n",
    "    return f\"Flightsaaaaa available from {location} on {date}: Flight AZjihad-101 at 10:00 AM, Flight AZ-202 at 5:00 PM.\"\n",
    "@tool\n",
    "#book a flight\n",
    "def book_flight(flight_id: str, passenger_name: str) -> str:\n",
    "    \"\"\"Book a flight with a given flight ID and passenger name.\"\"\"\n",
    "    return f\"Flight {flight_id} successfully booked for {passenger_name}.\"\n",
    "@tool\n",
    "def handle_complaint(complaint_text: str) -> str:\n",
    "    \"\"\"\n",
    "    Records the user's complaint into a file.\n",
    "    do not invent or give reasons , just provide the input user and fix grammer only when needed\n",
    "    Assumes the LLM has already extracted the pure complaint text.\n",
    "    \"\"\"\n",
    "    with open(\"customer_complaint.txt\", \"a\") as file:  # 'a' = append mode\n",
    "        file.write(complaint_text + \"\\n---\\n\")  # Add separator between complaints\n",
    "    return \"Your complaint has been recorded. We appreciate your feedback.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a99dd6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\desktop\\TFAjava\\AI\\TheAIEngineers-Exercises\\testenv1\\Lib\\site-packages\\gradio\\chat_interface.py:338: UserWarning: The 'tuples' format for chatbot messages is deprecated and will be removed in a future version of Gradio. Please set type='messages' instead, which uses openai-style 'role' and 'content' keys.\n",
      "  self.chatbot = Chatbot(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7866\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7866/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `handle_complaint` with `{'complaint_text': 'The drink is almost good and it can be better.'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[38;5;200m\u001b[1;3mYour complaint has been recorded. We appreciate your feedback.\u001b[0m\u001b[32;1m\u001b[1;3mYour complaint has been recorded. We appreciate your feedback.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `handle_complaint` with `{'complaint_text': 'also the drink'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[38;5;200m\u001b[1;3mYour complaint has been recorded. We appreciate your feedback.\u001b[0m\u001b[32;1m\u001b[1;3mYour complaint has been recorded. Thank you for your feedback.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# here i used the agent to automaticlly mange the flows between 2 tools\n",
    "#scnario 1 : Book a flight to jihad for roma \n",
    "#scnario 2: the food on the flight is so bad\n",
    "\n",
    "#The LLM reads my input and understands the logical dependencies between search_flights,book_flight\n",
    "#Calls search_flights() then Chooses the best flight now hardcoded\n",
    "\n",
    "#pass the arguments returned fro search_flights to  book_flight() using Aggnet (10x for Agents)\n",
    "# returned messagge\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "tools = [search_flights, book_flight, handle_complaint]\n",
    "\n",
    "\n",
    "\n",
    " #just telling the model what to do a semantic guidance dn not as setup\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \n",
    "     \"You are a helpful travel assistant. Use tools when needed. \"\n",
    "     \"If the user is making a complaint, use the 'handle_complaint' tool. \"\n",
    "     \"For flight search or booking, use the appropriate tools.\"),\n",
    "    (\"placeholder\", \"{chat_history}\"),\n",
    "    (\"human\", \"{input}\"),\n",
    "    (\"placeholder\", \"{agent_scratchpad}\")\n",
    "])\n",
    "\n",
    "openai_model_id = \"gpt-4o-mini\"\n",
    "##llm = ChatGoogleGenerativeAI(model=\"gemini-1.5-pro\")\n",
    "llm = ChatOpenAI(\n",
    "    model=openai_model_id,         \n",
    "    temperature=0,# make sure the same reply and standard responses especially in foundation\n",
    "    api_key=open_api_key\n",
    ")\n",
    "memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)\n",
    "\n",
    "agent = create_tool_calling_agent(llm, tools, prompt)\n",
    "\n",
    "agent_executor = AgentExecutor(\n",
    "    agent = agent,\n",
    "    tools = tools,\n",
    "    memory = memory,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "# Chat function for Gradio\n",
    "def chat_with_agent(message, history):\n",
    "    \"\"\"Filter out messages requesting travel to Kayan\"\"\"\n",
    "    if \"kayan\" in message.lower():\n",
    "        return \" Sorry, booking to 'Kayan' is not allowed.\"\n",
    "\n",
    "    # Normal agent flow\n",
    "    return agent_executor.invoke({\"input\": message})[\"output\"]\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    import gradio as gr\n",
    "    iface = gr.ChatInterface(\n",
    "        fn = chat_with_agent,\n",
    "        title=\"Flight  search\",\n",
    "        description=\"Chat with an AI find best flight!\",\n",
    "    )\n",
    "    iface.launch()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "testenv1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
